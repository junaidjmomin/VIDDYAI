"""
VidyaSetu AI ‚Äî STRICT RAG Retrieval Module

ANTI-HALLUCINATION VERSION

Key Guarantees:
‚úî Retrieval locked to student + subject
‚úî Weak chunks removed
‚úî Returns NONE when no grounded evidence exists
‚úî Limits context size
‚úî Forces evidence-based answering
"""

from typing import Optional, Tuple, List
from core.ingestion import get_collection, embed_query
from core.config import Config


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Helper: chunk builder
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _make_chunk(text: str, page: int, score: float, chunk_index: int) -> dict:
    return {
        "text": text,
        "page": page,
        "score": round(score, 4),
        "chunk_index": chunk_index,
    }


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Core Retrieval
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def retrieve_chunks(
    query: str,
    student_id: str,
    subject: str,
    k: int = None,
    min_score: float = None,
) -> List[dict]:

    k = k or Config.RAG_TOP_K
    min_score = min_score or Config.RAG_MIN_SCORE

    # Load collection
    try:
        collection = get_collection(student_id, subject)
    except Exception as e:
        print(f"[RAG] ‚ùå Collection missing: {student_id}/{subject}")
        return []

    total_docs = collection.count()
    if total_docs == 0:
        print(f"[RAG] ‚ùå Empty collection")
        return []

    query_emb = embed_query(query)
    n_results = min(k, total_docs)

    try:
        results = collection.query(
            query_embeddings=[query_emb],
            n_results=n_results,
            where={
                "$and": [
                    {"student_id": {"$eq": student_id}},
                    {"subject": {"$eq": subject}},
                ]
            },
            include=["documents", "distances", "metadatas"],
        )
    except Exception as e:
        print(f"[RAG] ‚ùå Query failed:", e)
        return []

    docs = results.get("documents", [[]])[0]
    distances = results.get("distances", [[]])[0]
    metadatas = results.get("metadatas", [[]])[0]

    if not docs:
        return []

    chunks = []

    # Convert cosine distance ‚Üí similarity
    for doc, dist, meta in zip(docs, distances, metadatas):
        similarity = 1.0 - dist

        # STRICT FILTER
        if similarity < min_score:
            print(
                f"[RAG] Dropping chunk "
                f"(score={similarity:.3f} < threshold={min_score})"
            )
            continue

        chunks.append(
            _make_chunk(
                text=doc,
                page=meta.get("page", 0),
                score=similarity,
                chunk_index=meta.get("chunk_index", -1),
            )
        )

    # Sort best ‚Üí worst
    chunks.sort(key=lambda c: c["score"], reverse=True)

    # üî• LIMIT CONTEXT SIZE (anti hallucination)
    chunks = chunks[:3]

    print(
        f"[RAG] ‚úÖ Retrieved {len(chunks)} grounded chunks "
        f"for query: '{query[:60]}‚Ä¶'"
    )

    return chunks


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Context Builder (STRICT MODE)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def retrieve_context(
    query: str,
    student_id: str,
    subject: str,
    k: int = None,
    min_score: float = None,
) -> Tuple[Optional[str], List[dict]]:

    chunks = retrieve_chunks(
        query,
        student_id,
        subject,
        k=k,
        min_score=min_score,
    )

    # üö® CRITICAL FIX
    # NO CONTEXT ‚Üí NO ANSWER
    if not chunks:
        print("[RAG] ‚ùå No grounded context found")
        return None, []

    parts = []

    for c in chunks:
        page_label = (
            f"Page {c['page']}" if c["page"] > 0 else "Textbook"
        )

        parts.append(
            f"[Source: {page_label} | Relevance: {c['score']:.2f}]\n"
            f"{c['text']}"
        )

    context_text = "\n\n---\n\n".join(parts)

    return context_text, chunks


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Citation Formatter
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def format_citations(chunks: List[dict]) -> str:

    if not chunks:
        return ""

    pages = sorted({c["page"] for c in chunks if c["page"] > 0})

    if not pages:
        return "üìñ Source: Your textbook"

    page_str = ", ".join(str(p) for p in pages)

    return (
        f"üìñ Source: Your textbook "
        f"(Page{'s' if len(pages) > 1 else ''} {page_str})"
    )